<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Interview-Review(Algorithm) | Hurley</title><meta name="description" content="本篇主要是面试复习内容的算法部分。   深度学习  模型评估方法   Accuracy作为指标有哪些局限性 准确率的定义是：分类正确的样本占总样本个数的比例，Accuracy=ncorrectntotalAccuracy = \frac{n_{correct}}{n_{total}}Accuracy=ntotal​ncorrect​​。但是此指标存在以下缺陷： 当正负样本非常不均衡时，占比大的类别"><meta name="keywords" content="面试"><meta name="author" content="Hurley"><meta name="copyright" content="Hurley"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/HurleyJames/ImageHosting/master/icon.png"><link rel="canonical" href="https://hurleyjames.github.io/2020/06/06/Interview-Review(Algorithm)/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="Interview-Review(Algorithm)"><meta property="og:url" content="https://hurleyjames.github.io/2020/06/06/Interview-Review(Algorithm)/"><meta property="og:site_name" content="Hurley"><meta property="og:description" content="本篇主要是面试复习内容的算法部分。   深度学习  模型评估方法   Accuracy作为指标有哪些局限性 准确率的定义是：分类正确的样本占总样本个数的比例，Accuracy=ncorrectntotalAccuracy = \frac{n_{correct}}{n_{total}}Accuracy=ntotal​ncorrect​​。但是此指标存在以下缺陷： 当正负样本非常不均衡时，占比大的类别"><meta property="og:image" content="https://hurleyjames.github.io/../image/algorithm-interview.png"><meta property="article:published_time" content="2020-06-05T16:00:00.000Z"><meta property="article:modified_time" content="2021-01-07T13:05:13.345Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="prev" title="Interview-Review(BigData)" href="https://hurleyjames.github.io/2020/06/06/Interview-Review(BigData)/"><link rel="next" title="Interview-Review(CloudComputing)" href="https://hurleyjames.github.io/2020/06/06/Interview-Review(CloudComputing)/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://avatars1.githubusercontent.com/u/26319720?s=460&amp;v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">71</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#深度学习"><span class="toc-number">1.</span> <span class="toc-text"> 深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型评估方法"><span class="toc-number">1.1.</span> <span class="toc-text"> 模型评估方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基本方法"><span class="toc-number">1.2.</span> <span class="toc-text"> 基本方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优化方法"><span class="toc-number">1.3.</span> <span class="toc-text"> 优化方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习基础"><span class="toc-number">1.4.</span> <span class="toc-text"> 深度学习基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cnn"><span class="toc-number">1.5.</span> <span class="toc-text"> CNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rnn"><span class="toc-number">1.6.</span> <span class="toc-text"> RNN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#机器学习"><span class="toc-number">2.</span> <span class="toc-text"> 机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基础"><span class="toc-number">2.1.</span> <span class="toc-text"> 基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#处理分类问题常用算法"><span class="toc-number">2.2.</span> <span class="toc-text"> 处理分类问题常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#逻辑回归"><span class="toc-number">2.2.1.</span> <span class="toc-text"> 逻辑回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#svm"><span class="toc-number">2.2.2.</span> <span class="toc-text"> SVM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#随机森林"><span class="toc-number">2.2.3.</span> <span class="toc-text"> 随机森林</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#朴素贝叶斯"><span class="toc-number">2.2.4.</span> <span class="toc-text"> 朴素贝叶斯</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#决策树"><span class="toc-number">2.2.5.</span> <span class="toc-text"> 决策树</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#处理回归问题常用算法"><span class="toc-number">2.3.</span> <span class="toc-text"> 处理回归问题常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#线性回归"><span class="toc-number">2.3.1.</span> <span class="toc-text"> 线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#普通最小二乘回归"><span class="toc-number">2.3.2.</span> <span class="toc-text"> 普通最小二乘回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#逐步回归"><span class="toc-number">2.3.3.</span> <span class="toc-text"> 逐步回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多元自适应回归样条"><span class="toc-number">2.3.4.</span> <span class="toc-text"> 多元自适应回归样条</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#处理聚类问题常用算法"><span class="toc-number">2.4.</span> <span class="toc-text"> 处理聚类问题常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#k均值基于划分的聚类"><span class="toc-number">2.4.1.</span> <span class="toc-text"> K均值（基于划分的聚类）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dbscan基于密度的聚类"><span class="toc-number">2.4.2.</span> <span class="toc-text"> DBSCAN（基于密度的聚类）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#lda"><span class="toc-number">2.4.3.</span> <span class="toc-text"> LDA</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#推荐系统常用算法"><span class="toc-number">2.5.</span> <span class="toc-text"> 推荐系统常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#协同过滤算法"><span class="toc-number">2.5.1.</span> <span class="toc-text"> 协同过滤算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fm"><span class="toc-number">2.5.2.</span> <span class="toc-text"> FM</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型融合和提升的常用算法"><span class="toc-number">2.6.</span> <span class="toc-text"> 模型融合和提升的常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bagging"><span class="toc-number">2.6.1.</span> <span class="toc-text"> Bagging</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#adaboost"><span class="toc-number">2.6.2.</span> <span class="toc-text"> Adaboost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gbdt"><span class="toc-number">2.6.3.</span> <span class="toc-text"> GBDT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gbrt"><span class="toc-number">2.6.4.</span> <span class="toc-text"> GBRT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#stacking"><span class="toc-number">2.6.5.</span> <span class="toc-text"> Stacking</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#blending"><span class="toc-number">2.6.6.</span> <span class="toc-text"> Blending</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#xgboost"><span class="toc-number">2.6.7.</span> <span class="toc-text"> XGBoost</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其它重要算法"><span class="toc-number">2.7.</span> <span class="toc-text"> 其它重要算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cv"><span class="toc-number">3.</span> <span class="toc-text"> CV</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nlp"><span class="toc-number">4.</span> <span class="toc-text"> NLP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用算法"><span class="toc-number">5.</span> <span class="toc-text"> 常用算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#搜索回溯"><span class="toc-number">5.1.</span> <span class="toc-text"> 搜索回溯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#概率题"><span class="toc-number">5.2.</span> <span class="toc-text"> 概率题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#动态规划"><span class="toc-number">5.3.</span> <span class="toc-text"> 动态规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#字符串"><span class="toc-number">5.4.</span> <span class="toc-text"> 字符串</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#海量数据"><span class="toc-number">5.5.</span> <span class="toc-text"> 海量数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基本概念"><span class="toc-number">6.</span> <span class="toc-text"> 基本概念</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/../image/algorithm-interview.png)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Hurley</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Interview-Review(Algorithm)</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-06 00:00:00"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2020-06-06</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-01-07 21:05:13"><i class="fas fa-history fa-fw"></i> 更新于 2021-01-07</span></time></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">6.2k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 20 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>本篇主要是面试复习内容的算法部分。</p>
<a id="more"></a>
<h2 id="深度学习"><a class="markdownIt-Anchor" href="#深度学习"></a> 深度学习</h2>
<h3 id="模型评估方法"><a class="markdownIt-Anchor" href="#模型评估方法"></a> 模型评估方法</h3>
<ol>
<li>
<p>Accuracy作为指标有哪些局限性</p>
<p>准确率的定义是：分类正确的样本占总样本个数的比例，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><msub><mi>n</mi><mrow><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow></msub><msub><mi>n</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub></mfrac></mrow><annotation encoding="application/x-tex">Accuracy = \frac{n_{correct}}{n_{total}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">c</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1623519999999998em;vertical-align:-0.4508599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7114919999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4508599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。但是此指标存在以下缺陷：</p>
<p>当正负样本非常不均衡时，占比大的类别就成为了影响准确率的主要因素，比如负样本占90%时，即使把所有样本都预测为负样本，也可以轻松获得90%的准确率，而这样的准确率是没有意义的，不足以说明分类器的好坏。</p>
</li>
<li>
<p>ROC曲线和PR曲线各是什么</p>
</li>
<li>
<p>编程实现AUC的计算，复杂度是多少</p>
</li>
<li>
<p>AUC指标有什么特点？放缩结果对AUC是否有影响</p>
</li>
<li>
<p>余弦距离与欧氏距离有什么特点</p>
</li>
</ol>
<h3 id="基本方法"><a class="markdownIt-Anchor" href="#基本方法"></a> 基本方法</h3>
<ol>
<li>
<p>如何划分训练集？如何选择验证集？</p>
<p>有以下几种不同的方法划分训练集与验证集：</p>
<ul>
<li>
<p>留出法：</p>
<ol>
<li>把数据集划分成互不相交的两部分，一部分作为训练集，一部分作为测试集；</li>
<li>保持数据的分布大致一致，类似分层抽样；</li>
<li>训练集数据所占比例应该为2/3或4/5左右</li>
<li>为了保证随机性，将数据集多次随机划分为训练集和测试集，然后再对多次划分的结果去平均</li>
</ol>
</li>
<li>
<p>k折交叉验证法：</p>
<ol>
<li>将数据集随机分为互斥的k个子集，为保证随机性，使用p次随机划分取平均；</li>
<li>将k个子集随机分为k-1个组，剩下一个为另一组，有k种分法；</li>
<li>在每一种方法的分组结果中，那个k-1个子集的组都作为训练集，剩下的一个组作为测试集，这样就产生了k次预测，并对其取平均；</li>
<li>这种方法称为p次k折交叉验证，一般k取10</li>
</ol>
</li>
<li>
<p>自助法：</p>
<ol>
<li>当样本量足够时，使用自助法不如使用留出法和交叉验证法，因为无法满足数据分布一致。而如果样本量较小，无法划分，就可以使用自助法；</li>
<li>每次随机从数据集中抽取一个样本，然后再放回（可能会被重复抽出），m次之后会得到有m个样本的数据集，将其作为训练集；</li>
<li>始终没有抽到的样本的比例按概率算约是36.8%，这也保证了训练集占比大概在2/3左右</li>
</ol>
</li>
</ul>
</li>
<li>
<p>什么是偏差和方差？</p>
</li>
<li>
<p>什么是过拟合？在深度学习中，解决过拟合的方法有哪些？</p>
<p>过拟合（overfitting）是指在模型参数拟合过程中的问题。由于训练数据包含了抽样误差，而训练时，复杂的模型将抽样的误差也考虑在内。</p>
<p>过拟合具体的表现就是最终模型在<strong>训练集</strong>上效果很好，但<strong>测试集</strong>上效果很差。模型的泛化能力弱。</p>
<p>产生过拟合的原因有：</p>
<ul>
<li>样本方面的原因。样本数量太少或者抽出的样本数据不能有效地代表场景；</li>
<li>样本里的噪声数据干扰过大，使得模型过分地记住了噪声特征，反而忽略了真实的输入输出间的关系；</li>
<li>参数太多以及模型复杂度高；</li>
</ul>
<p>降低过拟合的方法有：</p>
<ul>
<li>正则化：可以使用L0正则化、L1正则化或L2正则化，机器学习中一般采用L2正则化；</li>
<li>dropout：可以随机地，以一定的概率让一部分神经元失活或者丢弃；</li>
<li>batch normalization：BN在训练某层时，会对每一个batch数据都进行标准化或者叫归一化（normalization）处理，使得输出的规范呈正态分布；</li>
<li>early stopping：当随着模型的能力提升，训练集的误差会先减小后增大，所以可以提前终止算法缓解过拟合的现象（例如决策树的预剪枝方法）；</li>
<li>重新清洗数据：有可能是因为数据不纯导致的，所以需要重新清洗数据；</li>
<li>Data expending：增大数据的训练量。过拟合有可能是因为训练集的数据量太小导致的，或者训练数据占总数据的比例太小导致的；</li>
</ul>
</li>
<li>
<p>深度模型参数调整的一般方法论</p>
</li>
</ol>
<h3 id="优化方法"><a class="markdownIt-Anchor" href="#优化方法"></a> 优化方法</h3>
<ol>
<li>
<p>简述了解的优化器</p>
<ol>
<li>
<p>SGD(Stochastic Gradient Descent)</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>θ</mi><mo>−</mo><mi>η</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mrow><mo fence="true">(</mo><mi>θ</mi><mo separator="true">;</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">;</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i)} ; y^{(i)}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.63889em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2380099999999998em;vertical-align:-0.35001em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></p>
<p>SGD随机梯度下降参数的更新原则是<strong>一条数据都可以对参数进行一次更新</strong>。其它的优化器都是在这个优化器的基础上改善得来的。</p>
<p>优点：参数的更新速度快；</p>
<p>缺点：由于每次参数更新时采用的数据量小，造成梯度更新时的震荡幅度较大，但是大多数情况是向着梯度较小的方向；</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">    np.random.shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> data:</span><br><span class="line">        params_grad = eval_gradient(loss_function, example, params)</span><br><span class="line">        params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2020/05/25/tpQUgK.png" alt="" /></p>
<p>从上图可以看出，SGD的噪音较多，不是每次迭代都向着整体最优化方向。所以虽然训练速度快，但是准确率下降，并不是<strong>全局最优</strong>。</p>
</li>
<li>
<p>BGD(Batch Gradient Descent)</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>θ</mi><mo>−</mo><mi>η</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta=\theta-\eta \cdot \nabla_{\theta} J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.63889em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></p>
<p>BGD批量梯度下降的参数更新原则是：<strong>所有数据</strong>都参与梯度的每一次更新。</p>
<p>优点：因为每次参数更新时采用的数据量都非常大，所以梯度更新时比较平滑；</p>
<p>缺点：由于参数更新时需要的数据量大，所以更新的速度非常慢；</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">    params_grad = eval_gradient(loss_function, example, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>MBGD(Mini-Batch Gradient Descent)</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>θ</mi><mo>−</mo><mi>η</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mrow><mo fence="true">(</mo><mi>θ</mi><mo separator="true">;</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>:</mo><mi>i</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">;</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>:</mo><mi>i</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i: i+n)} ; y^{(i: i+n)}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.63889em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2380099999999998em;vertical-align:-0.35001em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></p>
<p>MBGD是每一次利用一小批样本，即<strong>n个样本</strong>进行计算，这样就可以<strong>降低参数更新时的方差，收敛更稳定</strong>。</p>
<p>优点：相比SGD，由于参与梯度更新的数据量大，所以梯度更新时较为平滑；相比BGD，参与梯度更新的数据量小，参数更新速度会更快一些。</p>
<p>缺点：</p>
<ol>
<li>如果数据是稀疏的，希望对出现频率低的特征进行更大的更，learning_rate会随着更新的次数逐渐变小；</li>
<li>不能保证很好的收敛性，learning_rate如果选择得太小，收敛速度会很慢，如果太大，loss_function就会在极小值处不停地震荡甚至偏离。</li>
</ol>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</span><br><span class="line">    np.random.shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> get_batches(data, batch_size=n):</span><br><span class="line">        params_grad = eval_gradient(loss_function, batch, patams)</span><br><span class="line">        params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>
<p>这里的<code>batch_size=n</code>的n一般取值在50~256之间。</p>
</li>
<li>
<p>Momentum</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>γ</mi><msub><mi>v</mi><mi>n</mi></msub><mo>+</mo><mi>η</mi><mi>θ</mi><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">v_{n+1}=\gamma v_{n}+\eta \theta J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><msup><mi>θ</mi><mi>n</mi></msup><mo>−</mo><msub><mi>v</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\theta^{n+1}=\theta^{n}-v_{n+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>Momenntum通过引入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi><msub><mi>v</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\gamma v_{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，加速SGD，并且抑制震荡。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span>一般取值为0.9左右，</p>
<p>优点：因为当我们将一个小球从山上滚下来时，没有阻力的话，它的动量就会越来越大，但是如果遇到了阻力，速度就会变小。所以加入了动量，**可以使得梯度方向不变的维度速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并且减小震荡。</p>
<p>缺点：当梯度方向改变时，梯度更新速度不能及时减小导致适应性差。</p>
</li>
<li>
<p>Adagrad(Adaptive gradient algorithm)</p>
<p>Adagrad解决了不能根据参数重要性而对不同参数进行不同程度更新的问题。它的参数更新原则是：对低频的参数做较大的更新，对高频的参数做较小的更新。一般超参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span>取值0.01。</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>θ</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><msub><mi>G</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi><mi>i</mi></mrow></msub><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⋅</mo><msub><mi>g</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot g_{t, i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.5771000000000002em;vertical-align:-0.8296000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.4986569999999997em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9876328571428572em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mord mtight"><span class="mord mathdefault mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">ϵ</span></span></span><span style="top:-2.959632857142857em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width='400em' height='1.5428571428571431em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4689385714285714em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">η</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8296000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>其中g是t时刻时参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的梯度。</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mrow><mo fence="true">(</mo><msub><mi>θ</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">g_{t, i}=\nabla_{\theta} J\left(\theta_{i}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></p>
<p>优点：对于稀疏的数据它的表现很好，很好地提高了SGD的鲁棒性。</p>
<p>缺点：它的缺点是分母会不断的积累，这样学习率就会收缩最终会变得非常小。</p>
</li>
<li>
<p>Adadelta</p>
<p>Adadelta解决的就是Adagrad的缺点，即分母不断积累，导致学习率收缩变得非常小的问题。</p>
<p>Adadelta的参数更新原则就是和Adagrad相比，将分母的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>i</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{t, i i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>换成了过去的梯度平方的衰减平均值，指数衰减平均值。</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mi>θ</mi><mi>t</mi></msub><mo>=</mo><mo>−</mo><mfrac><mi>η</mi><mrow><msqrt><mrow><mi>E</mi><msub><mrow><mo fence="true">[</mo><msup><mi>g</mi><mn>2</mn></msup><mo fence="true">]</mo></mrow><mi>t</mi></msub></mrow></msqrt><mo>+</mo><mi>ϵ</mi></mrow></mfrac><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \theta_{t}=-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}}+\epsilon} g_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.5771em;vertical-align:-0.8295999999999999em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.4891625em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0011964285714285em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">E</span><span class="minner mtight"><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">[</span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">]</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1179142857142857em;"><span style="top:-2.1785714285714284em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.32142857142857145em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.9731964285714287em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width='400em' height='1.5428571428571431em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4553750000000001em;"><span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">ϵ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">η</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8295999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>RMSprop</p>
<p>同样是为了解决Adagrad的学习率急剧下降的问题。参数更新原则同样是使用指数加权平均。</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><msub><mrow><mo fence="true">[</mo><msup><mi>g</mi><mn>2</mn></msup><mo fence="true">]</mo></mrow><mi>t</mi></msub><mo>=</mo><mn>0.9</mn><mi>E</mi><msub><mrow><mo fence="true">[</mo><msup><mi>g</mi><mn>2</mn></msup><mo fence="true">]</mo></mrow><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mn>0.1</mn><msubsup><mi>g</mi><mi>t</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">E\left[g^{2}\right]_{t}=0.9 E\left[g^{2}\right]_{t-1}+0.1 g_{t}^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2497099999999999em;vertical-align:-0.39971em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.03084599999999993em;"><span style="top:-2.3002900000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.39971em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.308041em;vertical-align:-0.45804100000000003em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.051397999999999944em;"><span style="top:-2.30029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.45804100000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.061108em;vertical-align:-0.247em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>t</mi></msub><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><mi>E</mi><mrow><mo fence="true">[</mo><msubsup><mi>g</mi><mi>t</mi><mn>2</mn></msubsup><mo fence="true">]</mo></mrow><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{E\left[g_{t}^{2}\right]+\epsilon}} g_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.7771000000000001em;vertical-align:-1.0296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.3416625em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2119107142857144em;"><span class="svg-align" style="top:-3.7142857142857144em;"><span class="pstrut" style="height:3.7142857142857144em;"></span><span class="mord mtight" style="padding-left:1.4285714285714286em;"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">E</span><span class="minner mtight"><span class="mopen sizing reset-size3 size6 mtight delimcenter" style="top:0.07500000000000001em;"><span class="mtight">[</span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051142857142858em;"><span style="top:-2.209457142857143em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29054285714285716em;"><span></span></span></span></span></span></span><span class="mclose sizing reset-size3 size6 mtight delimcenter" style="top:0.07500000000000001em;"><span class="mtight">]</span></span></span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">ϵ</span></span></span><span style="top:-3.183910714285714em;"><span class="pstrut" style="height:3.7142857142857144em;"></span><span class="hide-tail mtight" style="min-width:1.02em;height:1.8285714285714287em;"><svg width='400em' height='1.8285714285714287em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,
158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067
c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,
175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71
c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,
-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26
s76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.530375em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">η</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0296em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>超参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span></span></span></span>为0.9，学习率<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span>为0.001。</p>
</li>
<li>
<p>Adam(Adaptive Moment Estimation)</p>
<p>Adam相当于RMSprop+Momentum。</p>
</li>
</ol>
</li>
<li>
<p>常用的损失函数有哪些，分别适用于场景</p>
<p>损失函数是用来<strong>估量模型的预测值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>与真实值Y的不一致程度</strong>。它是一个非负实值函数，通常使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(Y, f(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>来表示。<strong>损失函数越小，模型的鲁棒性就越好</strong>。</p>
<ul>
<li>
<p>LogLoss对数损失函数</p>
<p>可以适用于<strong>逻辑回归，交叉熵损失</strong>等。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span>损失函数的标准形式是：</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(Y, P(Y | X))=-\log P(Y | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></p>
<p>softmax使用的是<strong>交叉熵损失函数</strong>，binary_crossentropy使用的是<strong>二分类交叉熵损失函数</strong>，categorical_crossentropy使用的是<strong>多分类交叉熵损失函数</strong>。</p>
</li>
<li>
<p>平方损失函数</p>
<p>可以适用于<strong>最小二乘法</strong>等。平方损失函数的标准形式如下：</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>Y</mi><mo>−</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L(Y, f(X))=(Y-f(X))^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>在实际应用中，通常使用均方差MSE作为一项衡量指标，公式如下：</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msup><mrow><mo fence="true">(</mo><msub><mover accent="true"><mi>Y</mi><mo>~</mo></mover><mi>i</mi></msub><mo>−</mo><msub><mi>Y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">M S E=\frac{1}{n} \sum_{i=1}^{n}\left(\tilde{Y}_{i}-Y_{i}\right)^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.004028em;vertical-align:-0.65002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">~</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.3540079999999999em;"><span style="top:-3.6029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>指数损失函数</p>
<p>可以使用于Adaboost算法。</p>
</li>
<li>
<p>Hinge损失函数</p>
<p>在机器学习算法中，hinge损失函数与SVM是息息相关的。其标准形式是：</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>y</mi><mover accent="true"><mi>y</mi><mo>~</mo></mover><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>y</mi><mo>=</mo><mo>±</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">L(y)=\max (0,1-y \tilde{y}), y=\pm 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">~</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">±</span><span class="mord">1</span></span></span></span></p>
</li>
<li>
<p>其它损失函数</p>
<p>0-1损失函数：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.15999999999999992em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>Y</mi><mi mathvariant="normal">≠</mi><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">L(Y, f(X))=\left\{\begin{array}{ll}
              1, &amp; Y \neq f(X) \\
              0, &amp; y=f(X)
              \end{array}\right.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mpunct">,</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>绝对值损失函数：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><mi>Y</mi><mo>−</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">L(Y, f(X))=|Y-f(X)|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mord">∣</span></span></span></span></p>
</li>
<li>
<p>Keras/Tensorflow中常用的cost function：</p>
<ul>
<li>mean_squared_error或者MSE</li>
<li>mean_absolute_error或者MAE</li>
<li>mean_absolute_percentage_error或者MAPE</li>
<li>mean_squared_logarithmic_error或者MSLE</li>
<li>squared_hinge</li>
<li>hinge</li>
<li>categorical_hinge</li>
<li>binary_crossentropy</li>
<li>logcosh</li>
<li>categorical_crossentropy</li>
</ul>
</li>
</ul>
</li>
<li>
<p>梯度下降与牛顿法、拟牛顿法的异同</p>
</li>
<li>
<p>L1和L2正则分别有什么特点？为什么L1更稀疏</p>
</li>
<li>
<p>如何提高小型网络的精度</p>
</li>
</ol>
<h3 id="深度学习基础"><a class="markdownIt-Anchor" href="#深度学习基础"></a> 深度学习基础</h3>
<ol>
<li>用一层隐藏层的神经网络，以ReLU作为激活函数，MSE作为损失函数推导反向传播</li>
<li>NN的权重参数能否初始化为0</li>
<li>什么是梯度消失和梯度爆炸，梯度爆炸的解决方法</li>
<li>常用的激活函数和导数</li>
<li>ReLU的优点和局限性，改进方法是什么</li>
<li>sigmoid和tanh为什么会导致梯度消失</li>
<li>相比sigmoid激活函数，ReLU激活函数有什么优势</li>
<li>一个隐藏层需要多少个节点能实现包含n元输入的任意布尔函数</li>
<li>多个隐藏层实现包含n元输入的任意布尔函数，需要多少个节点和网络层</li>
<li>Dropout为什么能够防止过拟合</li>
<li>Dropout和BN在前向传播和反向传播阶段的区别</li>
<li>解释批量归一化的原理</li>
<li>什么是反卷积，有哪些用途</li>
</ol>
<h3 id="cnn"><a class="markdownIt-Anchor" href="#cnn"></a> CNN</h3>
<ol>
<li>给定卷积核的尺寸，特征图大小的计算方法</li>
<li>网络容量的计算方法</li>
<li>共享参数有什么优点</li>
<li>常用的池化操作有哪些，有什么特点，池化层有什么作用</li>
<li>CNN如何用于文本分类</li>
<li>ResNet提出的背景和核心理论是什么</li>
<li>空洞卷积是什么？有什么应用场景，作用是什么</li>
</ol>
<h3 id="rnn"><a class="markdownIt-Anchor" href="#rnn"></a> RNN</h3>
<ol>
<li>简述RNN，LSTM，GRU的区别和联系</li>
<li>画出LSTM的结构图，写出公式</li>
<li>RNN的梯度消失问题，如何解决</li>
<li>LSTM中是否可以用ReLU作为激活函数</li>
<li>LSTM各个门分别使用什么作为激活函数</li>
<li>简述seq2seq模型</li>
<li>seq2seq在解码的时候有哪些方法</li>
<li>注意力机制是什么</li>
</ol>
<h2 id="机器学习"><a class="markdownIt-Anchor" href="#机器学习"></a> 机器学习</h2>
<h3 id="基础"><a class="markdownIt-Anchor" href="#基础"></a> 基础</h3>
<ol>
<li>
<p>样本不均衡如何处理（如何解决不平衡数据集的分类问题）</p>
<p>样本不均衡是指不同类别样本的比例相差悬殊，就会对算法的学习过程造成重大的干扰。例如，有1000个样本，只有5个正样本，995个负样本，那么算法把所有的样本都预测为负样本，精度也能达到99.5%。虽然精度很高，但是没有任何意义。</p>
<p>解决方法有：</p>
<ul>
<li>
<p>欠采样，减少数量较多的那一类的样本的数量，使得正负样本的比例均衡。</p>
<p>欠采样又分为随机欠采样、EasyEnsemble和BalanceCascade以及基于KNN欠采样。</p>
<ul>
<li>随机欠采样是指随机从多数类样本中抽取一部分数据进行删除。缺点就是未考虑到样本的分布情况，而采样过程又具有很大的随机性，可能会误删多数类样本中的一些重要信息。</li>
<li>EasyEnsemble是通过从多数的那一类样本中<strong>有放回</strong>的随机抽取一部分样本生成多个子数据集，将每个子集与少数类数据联合起来进行训练生成多个模型，然后综合多个模型的结果进行判断。方法和随机森林的原理很相似。</li>
<li>BalanceCascade是通过一次随机欠采样产生训练集，训练一个分类器，对于那些分类正确的多数类的样本不放回，然后剩下的多数类样本再次进行欠采样产生第二个训练器，训练第二个分类器，同样进行操作，以此类推，直到满足某个停止条件。最终的模型也是多个分类器的组合。</li>
<li>基于KNN欠采样：有四种KNN欠采样的方法。
<ul>
<li>NearMiss-1：选择到最近的三个少数类样本平均距离最小的那些多数类样本</li>
<li>NearMiss-2：选择到最远的三个少数类样本平均距离最小的那些多数类样本</li>
<li>NearMiss-3：为每个少数类样本选择给定数目的最近多数类样本，目的是保证每个少数类样本都被一些多数类样本包围</li>
<li>最远距离：选择到最近的三个少数类样本平均距离最大的那些多数类样本</li>
</ul>
</li>
</ul>
</li>
<li>
<p>过采样，增加数量较少的那一类的样本的数量，使得正负样本的比例均衡。</p>
<p>过采样又分为随机过采样、SMOTE算法和Borderline-SMOTE算法以及基于K-means过采样。</p>
<ul>
<li>随机过采样是指多次随机从少数类样本中有放回的抽取数据，采取数量大于原有的少数类样本的数量。其中的有一部分数据会出现重复，而重复数据的出现会增大方差造成模型的过拟合。</li>
<li>SMOTE的全称是Synthetic Minority Oversampling Technique，即合成少数类过采样技术。它是基于随机过采样算法的一种改机方案。SMOTE算法的基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中。</li>
<li>Borderline-SMOTE算法较SMOTE算法提升的地方是只为那些K近邻中有一半以上多数类样本的少数类样本生成新样本，因为这些样本容易被错分，而在这些少数类样本附近生存人工合成样本，有助于少数类样本的分类正确。而如果少数类样本周围全是多数类样本，这种情况下，这个样本会被认定为噪声样本。</li>
<li>基于K-means聚类过采样方法是首先分别对正负例进行K-means聚类，聚类之后，对其中较小的蔟进行上面的过采样方法扩充样本数量。然后再进行正负类样本的均衡扩充。</li>
</ul>
</li>
<li>
<p>不处理样本，样本分类阈值移动。</p>
</li>
</ul>
</li>
<li>
<p>什么是生成模型什么是判别模型</p>
</li>
<li>
<p>什么是鞍点问题</p>
</li>
<li>
<p>集成学习的分类？有什么代表性的模型和方法</p>
</li>
<li>
<p>常用的特征筛选方法有哪些</p>
</li>
<li>
<p>文本如何构造特征</p>
</li>
<li>
<p>类别变量如何构造特征</p>
</li>
<li>
<p>连续值变量如何构造特征</p>
</li>
<li>
<p>哪些模型需要对特征进行归一化</p>
</li>
<li>
<p>什么是组合特征？如何处理高维组合特征</p>
</li>
</ol>
<h3 id="处理分类问题常用算法"><a class="markdownIt-Anchor" href="#处理分类问题常用算法"></a> 处理分类问题常用算法</h3>
<h4 id="逻辑回归"><a class="markdownIt-Anchor" href="#逻辑回归"></a> 逻辑回归</h4>
<ol>
<li>
<p>逻辑回归怎么实现多分类</p>
<p>我们知道，普通的逻辑回归只能解决二分类问题。要想实现多分类，就要改进逻辑回归。</p>
<ol>
<li>第一种方式是One-Vs-All（或者叫One-Vs-Rest）。直接根据每个类别，都建立一个二分类器。带有这个类别的样本标记为1，带有其它样本的标记为0。如果有k个类别，那么最终就得到了k个针对不同标记的普通的逻辑分类器。</li>
<li>第二种方式是One-Vs-One。让不同类别的数据两两组合训练分类器。</li>
<li>第三种方式是修改逻辑回归的损失函数，让其适应多分类问题。即softmax回归。</li>
</ol>
</li>
<li>
<p>交叉熵公式</p>
</li>
<li>
<p>LR公式，LR的推导和损失函数</p>
</li>
<li>
<p>LR与SVM的区别和联系</p>
<p>相同点有：</p>
<ul>
<li>都是<strong>监督</strong>的分类算法</li>
<li>都会线性分类算法</li>
<li>都会判别模型</li>
</ul>
<p>不同点有：</p>
<ul>
<li>损失函数不同。LR的损失函数是cross entropy：，SVM的损失函数是最大化间隔距离：</li>
<li>SVM不能产生概率，LR可以产生概率</li>
<li>SVM依赖于数据的测度，而LR不受影响</li>
<li>SVM自带结构风险最小化，LR是经验风险最小化</li>
<li>SVM会用核函数而LR一般不用核函数的原因</li>
</ul>
</li>
<li>
<p>LR和线性回归的区别</p>
</li>
<li>
<p>为什么正则化可以防止过拟合（为什么L1和L2正则化可以降低过拟合）</p>
</li>
<li>
<p>L1正则和L2正则有什么区别</p>
</li>
<li>
<p>L1正则化不可导，怎么求解</p>
</li>
<li>
<p>逻辑回归为什么一般性能差</p>
</li>
<li>
<p>如何使用LR解决非线性问题</p>
</li>
</ol>
<h4 id="svm"><a class="markdownIt-Anchor" href="#svm"></a> SVM</h4>
<ol>
<li>SVM什么时候使用线性核，什么时候使用高斯核</li>
<li>SVM的作用和基本实现原理</li>
<li>SVM的硬间隔和软间隔表达式</li>
<li>SVM使用对偶计算的目的是什么，如何推导出来的，手写推导</li>
<li>SVM为什么要求解决对偶问题？为什么对偶问题与原问题等价</li>
<li>SVM的物理意义是什么</li>
<li>SVM的核函数的选择</li>
<li>SVM的核函数的作用</li>
<li>SVM的核函数的原理</li>
<li>SVM为什么采用间隔最大化（与感知机的区别）</li>
<li>为什么SVM对缺失数据敏感</li>
<li>SVM的优缺点</li>
<li>SVM如何调节惩罚因子C</li>
<li>如何处理SVM中样本不平衡的问题</li>
<li>SVM如何处理多分类问题</li>
<li>SVM对噪声敏感的原因</li>
<li>如何使用SMO最优化方法求解SVM模型</li>
<li>SMO算法优化的终止条件是什么</li>
<li>是否一定存在参数使得SVM的训练误差到0</li>
</ol>
<h4 id="随机森林"><a class="markdownIt-Anchor" href="#随机森林"></a> 随机森林</h4>
<ol>
<li>随机森林与SVM的区别</li>
<li>随机森林不会发生过拟合的原因</li>
<li>随机森林与梯度提升树（GBDT）的区别</li>
<li>随机森林是怎么避免ID3算法信息增益的缺点的</li>
<li>为什么随机森林能降低方差</li>
</ol>
<h4 id="朴素贝叶斯"><a class="markdownIt-Anchor" href="#朴素贝叶斯"></a> 朴素贝叶斯</h4>
<ol>
<li>朴素贝叶斯的要求（前提假设）是？</li>
<li>朴素贝叶斯算法原理和工作流程</li>
<li>什么是先验概率和后验概率</li>
<li>什么是条件概率</li>
<li>朴素贝叶斯为什么“朴素”</li>
<li>朴素贝叶斯可以做多分类吗</li>
<li>什么是朴素贝叶斯中的零概率问题？如何解决</li>
<li>朴素贝叶斯中概率计算的下溢问题如何解决</li>
<li>朴素贝叶斯分类器对异常值敏感吗</li>
<li>朴素贝叶斯对缺失值敏感吗</li>
<li>朴素贝叶斯有哪几种常用的分类模型</li>
<li>朴素贝叶斯算法中使用拉普拉斯平滑，拉普拉斯因子的大小如何确定</li>
<li>为什么说是朴素贝叶斯是高偏差低方差的</li>
<li>朴素贝叶斯为什么是增量计算</li>
<li>高度相关的特征对朴素贝叶斯有什么影响</li>
<li>朴素贝叶斯有什么优缺点</li>
</ol>
<h4 id="决策树"><a class="markdownIt-Anchor" href="#决策树"></a> 决策树</h4>
<ol>
<li>ID3，C4.5和CART三种决策树的区别</li>
<li>简述决策树的原理</li>
<li>简述决策树的构建过程</li>
<li>决策树有哪些划分指标，其区别和联系</li>
<li>信息增益率有什么优缺点</li>
<li>如何对决策树进行剪枝操作，为什么要进行剪枝</li>
<li>树模型如何调参</li>
<li>树模型如何剪枝</li>
<li>预剪枝和后剪枝</li>
<li>简述一下分类树和回归树</li>
<li>决策树对缺失值如何处理</li>
<li>如果决策树属性用完了，但仍未对决策树完成划分该怎么办</li>
<li>如何避免决策树的过拟合</li>
<li>决策树需要进行归一化处理吗</li>
<li>与其它模型比较，决策树有哪些优点和缺点</li>
</ol>
<h3 id="处理回归问题常用算法"><a class="markdownIt-Anchor" href="#处理回归问题常用算法"></a> 处理回归问题常用算法</h3>
<h4 id="线性回归"><a class="markdownIt-Anchor" href="#线性回归"></a> 线性回归</h4>
<ol>
<li>简单介绍一下线性回归的原理（什么是线性回归）</li>
<li>线性回归的求解方法有哪些</li>
<li>线性回归为什么用均方差</li>
</ol>
<h4 id="普通最小二乘回归"><a class="markdownIt-Anchor" href="#普通最小二乘回归"></a> 普通最小二乘回归</h4>
<ol>
<li>最小二乘法的推导</li>
<li>最小二乘法和梯度下降法有哪些区别</li>
</ol>
<h4 id="逐步回归"><a class="markdownIt-Anchor" href="#逐步回归"></a> 逐步回归</h4>
<ol>
<li>简述逐步回归算法</li>
</ol>
<h4 id="多元自适应回归样条"><a class="markdownIt-Anchor" href="#多元自适应回归样条"></a> 多元自适应回归样条</h4>
<ol>
<li>简述多元自适应回归样条</li>
</ol>
<h3 id="处理聚类问题常用算法"><a class="markdownIt-Anchor" href="#处理聚类问题常用算法"></a> 处理聚类问题常用算法</h3>
<h4 id="k均值基于划分的聚类"><a class="markdownIt-Anchor" href="#k均值基于划分的聚类"></a> K均值（基于划分的聚类）</h4>
<ol>
<li>简述一下K-means算法的原理和工作流程</li>
<li>K-means有什么缺点</li>
<li>K值如何确定</li>
<li>初始点选择方法</li>
<li>K-means不能处理哪种数据</li>
<li>K-means如何处理大数据（几十亿）</li>
<li>K-means与KNN有何不同</li>
</ol>
<h4 id="dbscan基于密度的聚类"><a class="markdownIt-Anchor" href="#dbscan基于密度的聚类"></a> DBSCAN（基于密度的聚类）</h4>
<ol>
<li>DBSCAN与传统的K-means的不同</li>
<li>DBSCAN的聚类法原理</li>
</ol>
<h4 id="lda"><a class="markdownIt-Anchor" href="#lda"></a> LDA</h4>
<h3 id="推荐系统常用算法"><a class="markdownIt-Anchor" href="#推荐系统常用算法"></a> 推荐系统常用算法</h3>
<h4 id="协同过滤算法"><a class="markdownIt-Anchor" href="#协同过滤算法"></a> 协同过滤算法</h4>
<ol>
<li>itemCF与userCF的区别和适用场景</li>
</ol>
<h4 id="fm"><a class="markdownIt-Anchor" href="#fm"></a> FM</h4>
<h3 id="模型融合和提升的常用算法"><a class="markdownIt-Anchor" href="#模型融合和提升的常用算法"></a> 模型融合和提升的常用算法</h3>
<h4 id="bagging"><a class="markdownIt-Anchor" href="#bagging"></a> Bagging</h4>
<h4 id="adaboost"><a class="markdownIt-Anchor" href="#adaboost"></a> Adaboost</h4>
<h4 id="gbdt"><a class="markdownIt-Anchor" href="#gbdt"></a> GBDT</h4>
<h4 id="gbrt"><a class="markdownIt-Anchor" href="#gbrt"></a> GBRT</h4>
<h4 id="stacking"><a class="markdownIt-Anchor" href="#stacking"></a> Stacking</h4>
<h4 id="blending"><a class="markdownIt-Anchor" href="#blending"></a> Blending</h4>
<h4 id="xgboost"><a class="markdownIt-Anchor" href="#xgboost"></a> XGBoost</h4>
<h3 id="其它重要算法"><a class="markdownIt-Anchor" href="#其它重要算法"></a> 其它重要算法</h3>
<h2 id="cv"><a class="markdownIt-Anchor" href="#cv"></a> CV</h2>
<h2 id="nlp"><a class="markdownIt-Anchor" href="#nlp"></a> NLP</h2>
<ol>
<li>word2vec的原理</li>
<li>glove的原理</li>
<li>fasttext的原理</li>
<li>了解elmo和bert吗？简述与word embedding的联系与趋避</li>
</ol>
<h2 id="常用算法"><a class="markdownIt-Anchor" href="#常用算法"></a> 常用算法</h2>
<h3 id="搜索回溯"><a class="markdownIt-Anchor" href="#搜索回溯"></a> 搜索回溯</h3>
<ol>
<li>八皇后，全排列，组合</li>
<li>重复数字的排列，重复数字的组合</li>
<li>图的搜索</li>
<li>A star</li>
</ol>
<h3 id="概率题"><a class="markdownIt-Anchor" href="#概率题"></a> 概率题</h3>
<ol>
<li>用rand7构造rand10</li>
<li>轮盘赌</li>
</ol>
<h3 id="动态规划"><a class="markdownIt-Anchor" href="#动态规划"></a> 动态规划</h3>
<ol>
<li>编辑距离</li>
<li>背包问题</li>
<li>LCS</li>
<li>备忘录方法</li>
</ol>
<h3 id="字符串"><a class="markdownIt-Anchor" href="#字符串"></a> 字符串</h3>
<ol>
<li>给定字符串是否符合正则表达式</li>
<li>给定字符串是否是数字</li>
<li>KMP</li>
<li>超大数相加</li>
</ol>
<h3 id="海量数据"><a class="markdownIt-Anchor" href="#海量数据"></a> 海量数据</h3>
<ol>
<li>海量日志的出现最多的K个字符串</li>
<li>10亿个1-10的数字排序</li>
<li>trie树</li>
<li>布隆过滤器</li>
</ol>
<h2 id="基本概念"><a class="markdownIt-Anchor" href="#基本概念"></a> 基本概念</h2>
<ol>
<li>算法的几个特征是什么</li>
<li>算法复杂性的定义，大O、θ、Ω、小o分别表示的含义</li>
<li>递归算法的定义、递归算法的两个要素</li>
<li>分治算法的思想</li>
<li>动态规划算法的两个要素是什么</li>
<li>贪心算法的思想，贪心算法的两个要素</li>
<li>回溯法的思想，回溯法中有哪两种典型的模型</li>
<li>分支限界法思想，有哪两种分支限界法</li>
</ol>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Hurley</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://hurleyjames.github.io/2020/06/06/Interview-Review(Algorithm)/">https://hurleyjames.github.io/2020/06/06/Interview-Review(Algorithm)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://hurleyjames.github.io" target="_blank">Hurley</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95/">面试</a></div><div class="post_share"><div class="social-share" data-image="/../image/dubbo.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/images/wechat.JPG" alt="wechat" onclick="window.open('/images/wechat.JPG')"/><div class="post-qr-code__desc">wechat</div></li><li class="reward-item"><img class="post-qr-code__img" src="/images/alipay.JPG" alt="alipay" onclick="window.open('/images/alipay.JPG')"/><div class="post-qr-code__desc">alipay</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/06/06/Interview-Review(BigData)/"><img class="prev-cover" data-src="/../image/big-data-interview.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Interview-Review(BigData)</div></div></a></div><div class="next-post pull-right"><a href="/2020/06/06/Interview-Review(CloudComputing)/"><img class="next-cover" data-src="/../image/cloud-computing-interview.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Interview-Review(CloudComputing)</div></div></a></div></nav></article></main><footer id="footer" style="background-image: url(/../image/algorithm-interview.png)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2021 By Hurley</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">随时意气风发，独自声势浩大</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>